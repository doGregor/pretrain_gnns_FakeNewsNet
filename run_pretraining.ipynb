{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e799d404-b697-4912-94cf-8eb466ee375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch_geometric\n",
    "from tqdm import tqdm\n",
    "from separate_pretraining import *\n",
    "from models import *\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "from predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed73ace-9d49-4b96-8d01-436cdc40d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'dataset': 'politifact', # 'politifact' or 'gossipcop'\n",
    "    'node_level_objective': None, # None or 'node_masking' or 'context_prediction'\n",
    "    'graph_level_objective': None, # None or 'rt'\n",
    "    'pretrained_model': None, # None or file name from previously trained model\n",
    "    'save_model': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f59302b-5963-4c50-87d6-73d077f1c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_by_path(file_name, dataset, setup):\n",
    "    path = \"../static_graphs/\" + dataset + \"/\" + setup + \"/\" + file_name + \".pickle\"\n",
    "    with open(path, 'rb') as handle:\n",
    "        return pickle.load(handle)['graph']\n",
    "\n",
    "def load_graph_ids(dataset):\n",
    "    file_path = '../' + dataset + '_train_test.pickle'\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        data = pickle.load(handle)['graph_ids']\n",
    "    return data\n",
    "\n",
    "def load_graphs_by_setup(setup, num_graphs=-1, dataset='politifact'):\n",
    "    graph_ids = load_graph_ids(dataset=dataset)\n",
    "    if num_graphs != -1:\n",
    "        graph_ids = graph_ids[:num_graphs]\n",
    "    all_graphs = []\n",
    "    for graph_id in tqdm(graph_ids):\n",
    "        graph = load_graph_by_path(file_name=graph_id, dataset=dataset, setup=setup)\n",
    "        graph['tweet'].x = graph['tweet'].x[:, :768]\n",
    "        graph['user'].x = graph['user'].x[:, :768]\n",
    "        all_graphs.append(graph)\n",
    "    return all_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b12291-4e6b-4873-ba8b-abbd83ae93f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12214/12214 [00:42<00:00, 285.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1marticle\u001b[0m={\n",
      "    x=[1, 768],\n",
      "    y=[1]\n",
      "  },\n",
      "  \u001b[1mtweet\u001b[0m={ x=[150, 768] },\n",
      "  \u001b[1muser\u001b[0m={ x=[25, 768] },\n",
      "  \u001b[1m(tweet, cites, article)\u001b[0m={ edge_index=[2, 25] },\n",
      "  \u001b[1m(user, posts, tweet)\u001b[0m={ edge_index=[2, 150] },\n",
      "  \u001b[1m(tweet, retweets, tweet)\u001b[0m={ edge_index=[2, 0] },\n",
      "  \u001b[1m(article, rev_cites, tweet)\u001b[0m={ edge_index=[2, 25] },\n",
      "  \u001b[1m(tweet, rev_posts, user)\u001b[0m={ edge_index=[2, 150] },\n",
      "  \u001b[1m(tweet, rev_retweets, tweet)\u001b[0m={ edge_index=[2, 0] }\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_graphs = load_graphs_by_setup('all_data', -1, CONFIG['dataset'])\n",
    "print(all_graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb924c4-86f0-40f2-b439-b4207fdab3ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001, loss: 1.3514, accuracy: 0.5031\n",
      "epoch: 002, loss: 1.2893, accuracy: 0.4903\n",
      "epoch: 003, loss: 1.2573, accuracy: 0.4695\n",
      "epoch: 004, loss: 1.2500, accuracy: 0.4466\n",
      "epoch: 005, loss: 1.2509, accuracy: 0.4369\n",
      "epoch: 006, loss: 1.2461, accuracy: 0.4422\n",
      "epoch: 007, loss: 1.2453, accuracy: 0.4466\n",
      "epoch: 008, loss: 1.2413, accuracy: 0.4440\n",
      "epoch: 009, loss: 1.2344, accuracy: 0.4456\n",
      "epoch: 010, loss: 1.2166, accuracy: 0.4424\n",
      "epoch: 011, loss: 1.2197, accuracy: 0.4406\n",
      "epoch: 012, loss: 1.2083, accuracy: 0.4429\n",
      "epoch: 013, loss: 1.2080, accuracy: 0.4426\n",
      "epoch: 014, loss: 1.2067, accuracy: 0.4417\n",
      "epoch: 015, loss: 1.2114, accuracy: 0.4429\n",
      "epoch: 016, loss: 1.2032, accuracy: 0.4425\n",
      "epoch: 017, loss: 1.2054, accuracy: 0.4432\n",
      "epoch: 018, loss: 1.1999, accuracy: 0.4435\n",
      "epoch: 019, loss: 1.2032, accuracy: 0.4424\n",
      "epoch: 020, loss: 1.2057, accuracy: 0.4427\n",
      "epoch: 021, loss: 1.1982, accuracy: 0.4422\n",
      "epoch: 022, loss: 1.2020, accuracy: 0.4423\n",
      "epoch: 023, loss: 1.2014, accuracy: 0.4431\n",
      "epoch: 024, loss: 1.1975, accuracy: 0.4422\n",
      "epoch: 025, loss: 1.2002, accuracy: 0.4423\n",
      "epoch: 026, loss: 1.2009, accuracy: 0.4423\n",
      "epoch: 027, loss: 1.1986, accuracy: 0.4429\n",
      "epoch: 028, loss: 1.1959, accuracy: 0.4436\n",
      "epoch: 029, loss: 1.2054, accuracy: 0.4440\n",
      "epoch: 030, loss: 1.1990, accuracy: 0.4425\n",
      "epoch: 031, loss: 1.1961, accuracy: 0.4432\n",
      "epoch: 032, loss: 1.1955, accuracy: 0.4445\n",
      "epoch: 033, loss: 1.2029, accuracy: 0.4418\n",
      "epoch: 034, loss: 1.2001, accuracy: 0.4429\n",
      "epoch: 035, loss: 1.1979, accuracy: 0.4429\n",
      "epoch: 036, loss: 1.1840, accuracy: 0.4409\n",
      "epoch: 037, loss: 1.1733, accuracy: 0.4423\n",
      "epoch: 038, loss: 1.1759, accuracy: 0.4423\n",
      "epoch: 039, loss: 1.1758, accuracy: 0.4426\n",
      "epoch: 040, loss: 1.1779, accuracy: 0.4422\n",
      "epoch: 041, loss: 1.1775, accuracy: 0.4427\n",
      "epoch: 042, loss: 1.1824, accuracy: 0.4438\n",
      "epoch: 043, loss: 1.1729, accuracy: 0.4419\n",
      "epoch: 044, loss: 1.1686, accuracy: 0.4406\n",
      "epoch: 045, loss: 1.1696, accuracy: 0.4418\n",
      "epoch: 046, loss: 1.1749, accuracy: 0.4435\n",
      "epoch: 047, loss: 1.1765, accuracy: 0.4430\n",
      "epoch: 048, loss: 1.1717, accuracy: 0.4431\n",
      "epoch: 049, loss: 1.1808, accuracy: 0.4424\n",
      "epoch: 050, loss: 1.1657, accuracy: 0.4421\n"
     ]
    }
   ],
   "source": [
    "if CONFIG['node_level_objective'] == 'context_prediction':\n",
    "    data_loader = DataLoader(all_graphs, batch_size=128, shuffle=True)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model_graph = HGT(hidden_channels=64, metadata=all_graphs[0].metadata(), out_cat=False, num_layers=2)\n",
    "    model_context = HGT(hidden_channels=64, metadata=get_context_graph(all_graphs[0]).metadata(), out_cat=True, num_layers=2)\n",
    "\n",
    "    optimizer_graph = optim.Adam(model_graph.parameters(), lr=0.001)\n",
    "    optimizer_context = optim.Adam(model_context.parameters(), lr=0.001)\n",
    "\n",
    "    loss, acc, model_graph = pretrain_context_prediction(model_graph=model_graph,\n",
    "                                                         model_context=model_context,\n",
    "                                                         data_loader=data_loader,\n",
    "                                                         optimizer_graph=optimizer_graph,\n",
    "                                                         optimizer_context=optimizer_context,\n",
    "                                                         criterion=criterion,\n",
    "                                                         epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3798de1-a129-4422-afdd-7e94114fa815",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['save_model'] == True:\n",
    "    torch.save(model_graph.state_dict(), \"pretrained_context.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da709c5-e018-406a-902c-0449ce7913f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001, loss: 0.1593\n",
      "epoch: 002, loss: 0.1005\n",
      "epoch: 003, loss: 0.0956\n",
      "epoch: 004, loss: 0.0938\n",
      "epoch: 005, loss: 0.0926\n",
      "epoch: 006, loss: 0.0918\n",
      "epoch: 007, loss: 0.0912\n",
      "epoch: 008, loss: 0.0907\n",
      "epoch: 009, loss: 0.0902\n",
      "epoch: 010, loss: 0.0898\n",
      "epoch: 011, loss: 0.0892\n",
      "epoch: 012, loss: 0.0890\n",
      "epoch: 013, loss: 0.0887\n",
      "epoch: 014, loss: 0.0886\n",
      "epoch: 015, loss: 0.0882\n",
      "epoch: 016, loss: 0.0879\n",
      "epoch: 017, loss: 0.0879\n",
      "epoch: 018, loss: 0.0877\n",
      "epoch: 019, loss: 0.0875\n",
      "epoch: 020, loss: 0.0871\n",
      "epoch: 021, loss: 0.0870\n",
      "epoch: 022, loss: 0.0869\n",
      "epoch: 023, loss: 0.0865\n",
      "epoch: 024, loss: 0.0864\n",
      "epoch: 025, loss: 0.0863\n",
      "epoch: 026, loss: 0.0862\n",
      "epoch: 027, loss: 0.0860\n",
      "epoch: 028, loss: 0.0858\n",
      "epoch: 029, loss: 0.0856\n",
      "epoch: 030, loss: 0.0855\n",
      "epoch: 031, loss: 0.0853\n",
      "epoch: 032, loss: 0.0852\n",
      "epoch: 033, loss: 0.0851\n",
      "epoch: 034, loss: 0.0849\n",
      "epoch: 035, loss: 0.0848\n",
      "epoch: 036, loss: 0.0847\n",
      "epoch: 037, loss: 0.0846\n",
      "epoch: 038, loss: 0.0844\n",
      "epoch: 039, loss: 0.0842\n",
      "epoch: 040, loss: 0.0843\n",
      "epoch: 041, loss: 0.0841\n",
      "epoch: 042, loss: 0.0840\n",
      "epoch: 043, loss: 0.0839\n",
      "epoch: 044, loss: 0.0839\n",
      "epoch: 045, loss: 0.0836\n",
      "epoch: 046, loss: 0.0836\n",
      "epoch: 047, loss: 0.0835\n",
      "epoch: 048, loss: 0.0835\n",
      "epoch: 049, loss: 0.0834\n",
      "epoch: 050, loss: 0.0832\n"
     ]
    }
   ],
   "source": [
    "if CONFIG['node_level_objective'] == 'node_masking':\n",
    "    encoder_model = HGT(hidden_channels=64, metadata=all_graphs[0].metadata())\n",
    "    encoder_optimizer = optim.Adam(encoder_model.parameters(), lr=0.001)\n",
    "\n",
    "    all_graphs = [mask_nodes(g, {'tweet': 1.0}) for g in all_graphs] # {'tweet': 1.0, 'user': 1.0}\n",
    "    data_loader = DataLoader(all_graphs, batch_size=128, shuffle=True)\n",
    "\n",
    "    encoder_model = pretrain_node_reconstruction(encoder_model=encoder_model,\n",
    "                                                 data_loader=data_loader,\n",
    "                                                 encoder_optimizer=encoder_optimizer,\n",
    "                                                 epochs=50,\n",
    "                                                 node_type='tweet',\n",
    "                                                 decoder_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14170774-b256-41f2-a252-ebf273c5a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['save_model'] == True:\n",
    "    torch.save(encoder_model.state_dict(), \"pretrained_nodes.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b882fdf-be13-42ba-9f25-44deb8ea5019",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 26.466709931691486\n",
      "epoch: 2 loss: 22.63671286900838\n",
      "epoch: 3 loss: 20.879405811429024\n",
      "epoch: 4 loss: 20.182606890797615\n",
      "epoch: 5 loss: 19.853272005915642\n",
      "epoch: 6 loss: 19.709533790747326\n",
      "epoch: 7 loss: 18.914485638340313\n",
      "epoch: 8 loss: 18.803261399269104\n",
      "epoch: 9 loss: 18.404570351044338\n",
      "epoch: 10 loss: 17.67037084698677\n",
      "epoch: 11 loss: 17.381763632098835\n",
      "epoch: 12 loss: 17.06446015338103\n",
      "epoch: 13 loss: 16.750875413417816\n",
      "epoch: 14 loss: 16.778749987483025\n",
      "epoch: 15 loss: 15.921978150804838\n",
      "epoch: 16 loss: 16.170435150464375\n",
      "epoch: 17 loss: 15.933606204887232\n",
      "epoch: 18 loss: 15.491712644696236\n",
      "epoch: 19 loss: 15.30548266073068\n",
      "epoch: 20 loss: 14.79008573293686\n",
      "epoch: 21 loss: 15.545309091607729\n",
      "epoch: 22 loss: 15.23928415775299\n",
      "epoch: 23 loss: 15.016981825232506\n",
      "epoch: 24 loss: 14.400368998448053\n",
      "epoch: 25 loss: 14.315298850337664\n",
      "epoch: 26 loss: 14.129013513525328\n",
      "epoch: 27 loss: 14.453448424736658\n",
      "epoch: 28 loss: 13.927411948641142\n",
      "epoch: 29 loss: 13.77347075442473\n",
      "epoch: 30 loss: 13.936801210045815\n",
      "epoch: 31 loss: 13.692059993743896\n",
      "epoch: 32 loss: 14.345347026983896\n",
      "epoch: 33 loss: 14.597302198410034\n",
      "epoch: 34 loss: 15.199262465039888\n",
      "epoch: 35 loss: 14.444861431916555\n",
      "epoch: 36 loss: 13.879920601844788\n",
      "epoch: 37 loss: 13.347148446987072\n",
      "epoch: 38 loss: 13.155561948815981\n",
      "epoch: 39 loss: 13.599241572121779\n",
      "epoch: 40 loss: 12.74128387371699\n",
      "epoch: 41 loss: 12.966396197676659\n",
      "epoch: 42 loss: 12.529049895703793\n",
      "epoch: 43 loss: 12.884846965471903\n",
      "epoch: 44 loss: 12.482627128561338\n",
      "epoch: 45 loss: 12.419631054004034\n",
      "epoch: 46 loss: 12.565394667287668\n",
      "epoch: 47 loss: 11.949656436840693\n",
      "epoch: 48 loss: 12.398290480176607\n",
      "epoch: 49 loss: 11.763152793049812\n",
      "epoch: 50 loss: 12.077902605136236\n"
     ]
    }
   ],
   "source": [
    "if CONFIG['graph_level_objective'] == 'rt':\n",
    "    encoder_model = HGT(hidden_channels=64, metadata=all_graphs[0].metadata())\n",
    "    \n",
    "    if CONFIG['pretrained_model'] is not None:\n",
    "        encoder_model.load_state_dict(torch.load(CONFIG['pretrained_model'] + '.pth'))\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder_model.parameters(), lr=0.001)\n",
    "\n",
    "    all_graphs = [add_rt_count(g) for g in all_graphs]\n",
    "\n",
    "    data_loader = DataLoader(all_graphs, batch_size=128, shuffle=True)\n",
    "\n",
    "    encoder_model = pretrain_graph_level(encoder_model=encoder_model,\n",
    "                                         data_loader=data_loader,\n",
    "                                         encoder_optimizer=encoder_optimizer,\n",
    "                                         epochs=50,\n",
    "                                         decoder_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62b610b-14a5-4da7-8009-c0e6719840cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['save_model'] == True:\n",
    "    if CONFIG['pretrained_model'] is not None:\n",
    "        torch.save(encoder_model.state_dict(), CONFIG['pretrained_model'] + \"_rt.pth\")\n",
    "    else:\n",
    "        torch.save(encoder_model.state_dict(), \"rt.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
